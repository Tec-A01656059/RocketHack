{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "## Loading and exploring data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "## Topological data analysis\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the data\n",
    "sales=pd.read_csv('sales.csv')\n",
    "\n",
    "# Remove clients with less than 24 registered sales\n",
    "customers = sales['customer_id'].value_counts()\n",
    "customers = customers[customers >= 24].index\n",
    "sales2 = sales[sales['customer_id'].isin(customers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values in 'churn_next_month'\n",
    "sales2=sales2.dropna(subset='churn_next_month')\n",
    "\n",
    "# Rename column 'churn_next_month' to 'target'\n",
    "sales2.rename(columns={'churn_next_month': 'target'}, inplace=True)\n",
    "\n",
    "# Sort values by 'customer_id' and 'month'\n",
    "sales2 = sales2.sort_values(by=['customer_id', 'month'])\n",
    "df = sales2\n",
    "\n",
    "# Join all sales of a customer in a single row, as a pseudo-time series\n",
    "pivot_df = df.pivot_table(index='customer_id', columns='month', values='amount', aggfunc='sum')\n",
    "target_sum = df.groupby('customer_id')['target'].sum()\n",
    "pivot_df = pivot_df.join(target_sum)\n",
    "\n",
    "# Rename columns as order of observation\n",
    "pivot_df = pivot_df.rename(columns=lambda x: f'month_{x}' if isinstance(x, int) else x)\n",
    "pivot_df.reset_index(inplace=True)\n",
    "df = pivot_df\n",
    "\n",
    "# Displace all non-null values to the end of the row\n",
    "def move_non_nulls_to_end(row):\n",
    "    '''\n",
    "    This functuon moves all non-null values to the end of the row.\n",
    "\n",
    "    Args: a row of a DataFrame (pd.Series)\n",
    "\n",
    "    Output: the input row with non-null values moved to the end (pd.Series)\n",
    "    '''\n",
    "    non_nulls = row.dropna().tolist()\n",
    "    nulls = [np.nan] * (len(row) - len(non_nulls))\n",
    "    return pd.Series(nulls + non_nulls)\n",
    "\n",
    "\n",
    "df_shifted = df.copy()\n",
    "\n",
    "# In the neew DataFrame, move all non-null values to the end of the row\n",
    "df_shifted.iloc[:, 1:] = df.iloc[:, 1:].apply(move_non_nulls_to_end, axis=1)\n",
    "\n",
    "# Replace null values with 0\n",
    "df_shifted = df_shifted.fillna(0)\n",
    "df=df_shifted\n",
    "\n",
    "# Remove first and last columns\n",
    "columns = df.columns[1:-1]\n",
    "\n",
    "# Calculate the percentage change of each column with respect to the previous one\n",
    "df_percent_change = df[columns].pct_change(axis=1) * 100\n",
    "\n",
    "# Replace infinite values with 100\n",
    "df_percent_change.replace([np.inf, -np.inf], 100, inplace=True)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "df_percent_change.fillna(0, inplace=True)\n",
    "\n",
    "# Add the first and last columns (customer_id and target)\n",
    "df_percent_change.insert(0, 'ID', df.iloc[:, 0])\n",
    "df_percent_change['target'] = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "iterable expected, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_homology\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mError\u001b[0m: iterable expected, not int"
     ]
    }
   ],
   "source": [
    "id_homology = df_percent_change['ID']\n",
    "\n",
    "filename = 'birthdeath_id.csv'\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(id_homology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time series to point cloud\n",
    "persistence1 = SingleTakensEmbedding(parameters_type=\"search\", n_jobs=-1)\n",
    "\n",
    "# Calculate the persistence diagram\n",
    "homology = VietorisRipsPersistence(metric=\"euclidean\", homology_dimensions=(0, 1), n_jobs=-1)\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the persistence diagram for each row (client)\n",
    "homo_diags = []\n",
    "for i in range(len(df_percent_change)):\n",
    "    ts = pd.Series(df_percent_change.iloc[i, 1:-1])         # convert row to pd series\n",
    "    SOI = ts.values.reshape(-1)                             # keep pnly values\n",
    "    diagram = persistence1.fit_transform(SOI)               # fit Takens embedding to data\n",
    "    diagram = diagram.reshape(1,*diagram.shape)             # Adjust shape\n",
    "    diag = diagram[0]\n",
    "    comps_pure = pca.fit_transform(diag)                    # Apply PCA to data\n",
    "    comps = comps_pure.reshape(1, *comps_pure.shape)        # adjust sizes\n",
    "    homology_diagram = homology.fit_transform(comps)        # fit Vietoris- Rips embedding\n",
    "    homo_diags.append(homology_diagram)\n",
    "    #print(diagram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Bett numbers 1\n",
    "\n",
    "b1 = []\n",
    "for i in range(len(homo_diags)):\n",
    "    diagramas = homo_diags[i][0]                                    # recover data of H0 and H1 (birth, death, tyoe)\n",
    "    b_1 = []\n",
    "    for j in range(len(diagramas)):\n",
    "        if diagramas[j][2] == 1:                                    # Compute lifespan in relation to H0 and H1\n",
    "            b_1.append(np.abs(diagramas[j][0] - diagramas[j][1]))   # Join previous result to Beta_1\n",
    "    b_1.sort()\n",
    "    b_1.reverse()                                                   # Order from largest to smallest lifespan\n",
    "    b_1 = b_1[:3]\n",
    "    b1.append(b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filename\n",
    "filename = 'homology_output.csv'\n",
    "\n",
    "# Write CSV for homology\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(homo_diags)\n",
    "\n",
    "# Write CSV for homology summary :)\n",
    "filename = 'birthdeath_output.csv'\n",
    "\n",
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(b1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
